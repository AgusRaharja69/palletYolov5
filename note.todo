py train.py --img 320 --batch 8 --epochs 50 --data data.yaml --device 0 --weights yolov5n.pt
py train.py --img 320 --batch 8 --epochs 10 --data data.yaml --device 0 --weights yolov5n.pt

py detectPallet.py --source 1 --device 0 --weights runs/train/exp21/weights/best.pt --weights-name yolov5n-100 --img 320

py yoloDetection.py --weights runs/train/exp16/weights/best.pt --weights-name yolov5s-100 --img 320
- yolov5m-10 : exp11
- yolov5m-25 : exp12
- yolov5m-50 : exp13
- yolov5m-75 : exp14
- yolov5m-100 : exp15

- yolov5s-100 : exp16
- yolov5s-75 : exp17
- yolov5s-50 : exp18
- yolov5s-25 : exp19
- yolov5s-10 : exp20

- yolov5n-100 : exp21
- yolov5n-75 : exp22
- yolov5n-50 : exp23
- yolov5n-25 : exp27
- yolov5n-10 : exp28
yolov5m [952.0,954.0,954.0,952.0,954.0,952.0,952.0,952.0,952.0,954.0,952.0,952.0,954.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0,954.0,952.0,952.0,954.0,954.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0,954.0,952.0,952.0,954.0,952.0,952.0,952.0,954.0,952.0,952.0,952.0,952.0,952.0,952.0,954.0,954.0,952.0]
yolov5s [992.0,988.0,988.0,980.0,988.0,996.0,986.0,986.0,992.0,984.0,984.0,990.0,996.0,994.0,996.0,986.0,990.0,994.0,988.0,996.0,982.0,994.0,980.0,980.0,992.0,988.0,990.0,990.0,990.0,990.0,996.0,996.0,992.0,998.0,998.0,992.0,990.0,986.0,982.0,994.0,984.0,994.0,990.0,982.0,988.0,988.0,984.0,996.0,980.0,994.0,988.0,990.0,984.0,990.0,992.0,986.0,996.0,996.0,974.0,988.0,988.0,978.0,988.0,990.0,990.0,990.0,976.0,978.0,988.0,986.0,990.0,990.0,998.0,992.0,982.0,992.0,992.0,988.0,990.0,990.0,986.0,990.0,986.0,992.0,990.0,992.0,994.0,994.0,994.0,994.0,990.0,990.0,992.0,986.0,992.0,994.0,994.0,986.0,992.0,994.0,984.0,990.0,998.0,992.0,988.0,994.0,984.0,980.0,982.0,994.0,994.0,982.0,994.0,982.0,982.0,992.0,992.0,994.0,994.0,992.0,992.0,990.0,994.0,982.0,994.0,984.0,984.0,992.0,994.0,996.0,992.0,992.0,986.0,994.0,990.0,980.0,988.0,988.0,970.0,988.0,988.0,982.0,982.0,990.0,990.0,986.0,990.0,990.0,988.0,992.0,994.0,980.0,994.0,988.0,990.0,986.0,982.0]
yolov5n [980.0,982.0,970.0,982.0,966.0,966.0,976.0,980.0,986.0,982.0,962.0,980.0,968.0,976.0,962.0,968.0,968.0,984.0,980.0,984.0,982.0,976.0,978.0,972.0,974.0,984.0,988.0,976.0,954.0,974.0,974.0,976.0,976.0,974.0,974.0,980.0,974.0,968.0,968.0,982.0,972.0,978.0,978.0,976.0,980.0,956.0,972.0,980.0,954.0,976.0,980.0,978.0,988.0,980.0,978.0,978.0,978.0,976.0,976.0,984.0,964.0,964.0,982.0,978.0,984.0,964.0,988.0,988.0,980.0,992.0]
! 100
m1 (99.797) = [99.655,99.864,99.864,99.864,99.655,99.865,99.655,99.864,99.655,99.655,99.865,99.655,99.655,100.074,99.864,100.074,99.865,99.655,99.655,99.864,99.655,99.864,99.864,99.864,99.864,99.655,99.655,99.655,99.864,99.864,100.074]
100.305
0: 256x320 1 Wooden-Pallet, 2069.2ms 100.515, 0: 256x320 1 Wooden-Pallet, 62.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 61.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 59.4ms 100.305, 0: 256x320 1 Wooden-Pallet, 57.2ms 100.092, 0: 256x320 1 Wooden-Pallet, 66.8ms 100.515, 0: 256x320 1 Wooden-Pallet, 61.8ms 100.515, 0: 256x320 1 Wooden-Pallet, 63.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 60.8ms 100.515, 0: 256x320 1 Wooden-Pallet, 56.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 62.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 55.8ms 100.515, 0: 256x320 1 Wooden-Pallet, 62.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 56.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 64.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 59.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 56.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 55.9ms 100.303, 0: 256x320 1 Wooden-Pallet, 59.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 60.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 60.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 56.9ms 100.305, 0: 256x320 1 Wooden-Pallet, 60.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 55.9ms 100.515, 0: 256x320 1 Wooden-Pallet, 62.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.092, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.305, 0: 256x320 1 Wooden-Pallet, 57.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 62.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.305, 0: 256x320 1 Wooden-Pallet, 61.8ms 100.305, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.515, 0: 256x320 1 Wooden-Pallet, 62.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 61.1ms 100.515, 0: 256x320 1 Wooden-Pallet, 58.8ms 100.515, 0: 256x320 1 Wooden-Pallet, 56.4ms 100.305, 0: 256x320 1 Wooden-Pallet, 57.4ms 100.303, 0: 256x320 1 Wooden-Pallet, 56.8ms 100.305, 0: 256x320 1 Wooden-Pallet, 57.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 60.8ms 100.305, 0: 256x320 1 Wooden-Pallet, 56.8ms 100.305, 0: 256x320 1 Wooden-Pallet, 56.9ms 100.303, 0: 256x320 1 Wooden-Pallet, 55.8ms 100.303, 0: 256x320 1 Wooden-Pallet, 58.1ms 100.092, 0: 256x320 1 Wooden-Pallet, 57.0ms 100.303, 0: 256x320 1 Wooden-Pallet, 160.0ms 100.303, 0: 256x320 1 Wooden-Pallet, 128.1ms 100.305, 0: 256x320 1 Wooden-Pallet, 124.5ms 100.515, 0: 256x320 1 Wooden-Pallet, 76.0ms 100.303, 0: 256x320 1 Wooden-Pallet, 98.0ms 100.305, 0: 256x320 1 Wooden-Pallet, 66.0ms 100.515, 0: 256x320 1 Wooden-Pallet, 53.0ms 100.515, 0: 256x320 1 Wooden-Pallet, 55.4ms 100.305, 0: 256x320 1 Wooden-Pallet, 54.9ms 100.305, 0: 256x320 1 Wooden-Pallet, 56.1ms 100.092, 0: 256x320 1 Wooden-Pallet, 50.9ms 100.303, 0: 256x320 1 Wooden-Pallet, 53.0ms 100.305, 0: 256x320 1 Wooden-Pallet, 54.9ms 100.305, 0: 256x320 1 Wooden-Pallet, 53.9ms 100.515, 0: 256x320 1 Wooden-Pallet, 54.9ms 100.305, 0: 256x320 1 Wooden-Pallet, 54.9ms 100.303, 0: 256x320 1 Wooden-Pallet, 53.9ms 100.305, 0: 256x320 1 Wooden-Pallet, 52.4ms 100.092, 0: 256x320 1 Wooden-Pallet, 53.4ms 100.515, 0: 256x320 1 Wooden-Pallet, 54.1ms 100.303, 0: 256x320 1 Wooden-Pallet, 54.9ms 100.305, 0: 256x320 1 Wooden-Pallet, 51.9ms 100.515, 0: 256x320 1 Wooden-Pallet, 54.0ms 
s1 (101.208) = [101.34,101.34,101.132,101.132,100.927,101.132,100.721,101.133,103.039,101.132,101.34,101.133,101.133,101.133,100.927,101.134,101.34,101.133,101.34,101.133,101.133,101.133,101.34,101.133,100.927,100.927,101.132,100.927,101.133,101.34,101.548]
n1 (102.874) = [103.387,103.169,105.863,102.515,102.515,103.609,102.517,102.302,101.661,102.302,102.302,104.051,102.517,102.517,102.517,100.818,102.302,102.951,102.951,103.609,102.517,102.517,102.517,101.875,102.951,103.829,103.829,102.951,102.086,104.053,103.609]
! 150
! 200
! 250
! 300
! 350

=============
1
im  [[[  0   0   2]
  [  0   0   2]
  [  0   0   2]
  ...
  [190 187 192]
  [191 187 192]
  [193 190 194]]

 [[  0   0   7]
  [  0   0   5]
  [  0   0   4]
  ...
  [191 189 191]
  [190 189 191]
  [190 189 191]]

 [[  0   0  10]
  [  0   0   6]
  [  0   0   4]
  ...
  [188 188 191]
  [188 188 190]
  [188 188 190]]

 ...

 [[176 189 192]
  [178 190 193]
  [180 191 194]
  ...
  [229 227 230]
  [232 230 232]
  [232 230 232]]

 [[172 190 190]
  [174 190 190]
  [178 192 193]
  ...
  [221 220 225]
  [225 224 228]
  [228 227 232]]

 [[175 187 195]
  [176 188 194]
  [177 190 193]
  ...
  [225 224 226]
  [220 219 222]
  [221 221 223]]]
det  tensor([[3.30000e+01, 1.79000e+02, 5.45000e+02, 3.40000e+02, 9.29101e-01, 0.00000e+00],
        [1.00000e+00, 2.70000e+02, 2.30000e+01, 3.18000e+02, 5.57366e-01, 0.00000e+00],
        [2.79000e+02, 1.56000e+02, 4.73000e+02, 2.01000e+02, 4.34552e-01, 0.00000e+00]], device='cuda:0')
det 4  tensor([[ 33., 179., 545., 340.],
        [  1., 270.,  23., 318.],
        [279., 156., 473., 201.]], device='cuda:0')
rev det  tensor([[2.79000e+02, 1.56000e+02, 4.73000e+02, 2.01000e+02, 4.34552e-01, 0.00000e+00],
        [1.00000e+00, 2.70000e+02, 2.30000e+01, 3.18000e+02, 5.57366e-01, 0.00000e+00],
        [3.30000e+01, 1.79000e+02, 5.45000e+02, 3.40000e+02, 9.29101e-01, 0.00000e+00]], device='cuda:0')=============




=============
det 4  tensor([[ 77., 183., 351., 278.],
        [408., 198., 636., 264.]], device='cuda:0')
det  tensor([[7.70000e+01, 1.83000e+02, 3.51000e+02, 2.78000e+02, 8.54158e-01, 0.00000e+00],
        [4.08000e+02, 1.98000e+02, 6.36000e+02, 2.64000e+02, 3.11553e-01, 0.00000e+00]], device='cuda:0')       
rev det  tensor([[4.08000e+02, 1.98000e+02, 6.36000e+02, 2.64000e+02, 3.11553e-01, 0.00000e+00],
        [7.70000e+01, 1.83000e+02, 3.51000e+02, 2.78000e+02, 8.54158e-01, 0.00000e+00]], device='cuda:0')       
=============


yoloDetection.py
        # Process predictions
        for i, det in enumerate(pred):  # per image
            seen += 1                
            p, im0, frame = path[i], im0s[i].copy(), dataset.count
            s += f'{i}: '
            # txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt
            s += '%gx%g ' % im.shape[2:]  # print string
            # gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            # imc = im0.copy() if save_crop else im0  # for save_crop
            # annotator = Annotator(im0, line_width=line_thickness, example=str(names))
            # print(i)
            print("=============")
            # print(p)
            # print("im ",im0)
            # print("det ", det)
            if len(det):
                # Rescale boxes from img_size to im0 size
                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()                
                print("det 4 ", det[:, :4])
                

                # Print results
                for c in det[:, 5].unique():
                    n = (det[:, 5] == c).sum()  # detections per class
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                print("det ", det)
                print("rev det ", reversed(det))
                # Write results
                for *xyxy, conf, cls in (det):                   
                    lw = line_thickness or max(round(sum(im0.shape) / 2 * 0.003), 2)
                    txt_color=(255, 255, 255)

                    c = int(cls)  # integer class
                    color=(10, 15, 255)
                    label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')

                    p1, p2 = (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3]))
                    cv2.rectangle(im0, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)
                    if label:
                        tf = max(lw - 1, 1)  # font thickness
                        w, h = cv2.getTextSize(label, 0, fontScale=lw / 3, thickness=tf)[0]  # text width, height
                        outside = p1[1] - h >= 3
                        p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3
                        cv2.rectangle(im0, p1, p2, color, -1, cv2.LINE_AA)  # filled
                        cv2.putText(im0,
                                    label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2),
                                    0,
                                    lw / 3,
                                    txt_color,
                                    thickness=tf,
                                    lineType=cv2.LINE_AA)                                  
                    

            # Stream results
            im0 = np.asarray(im0)
            if view_img:
                if platform.system() == 'Linux' and p not in windows:
                    windows.append(p)
                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)
                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])
                cv2.imshow(str(p), im0)
                cv2.waitKey(1)  # 1 millisecond